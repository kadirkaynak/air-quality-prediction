{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b062717",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import locale\n",
    "from locale import atof\n",
    "import xlsxwriter\n",
    "\n",
    "from utilities.PreProcessingUtil import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1028e6b",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                    Tarih PM10 ( µg/m3 ) SO2 ( µg/m3 ) CO ( µg/m3 )  \\\n0     2012-01-01 01:00:56              -             -            -   \n1     2012-01-01 02:00:56              -             -            -   \n2     2012-01-01 03:00:56              -             -            -   \n3     2012-01-01 04:00:56              -             -            -   \n4     2012-01-01 05:00:56              -             -            -   \n...                   ...            ...           ...          ...   \n81690 2021-04-26 19:00:56          11,10          1,00       296,70   \n81691 2021-04-26 20:00:56          17,40          0,80       254,10   \n81692 2021-04-26 21:00:56          30,00          0,70       180,00   \n81693 2021-04-26 22:00:56          18,60          1,00       399,00   \n81694 2021-04-26 23:00:56              -          1,10       446,60   \n\n      NO2 ( µg/m3 ) NOX ( µg/m3 ) O3 ( µg/m3 ) PM 2.5 ( µg/m3 )  \n0                 -             -            -                -  \n1                 -             -            -                -  \n2                 -             -            -                -  \n3                 -             -            -                -  \n4                 -             -            -                -  \n...             ...           ...          ...              ...  \n81690         15,90             -        31,60                -  \n81691         15,80             -        34,40                -  \n81692         18,90             -        31,70                -  \n81693         23,30             -        17,10                -  \n81694         22,10             -        22,20                -  \n\n[81695 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel(\n",
    "     os.path.join(\"datasets\", \"pollutants\", \"besiktas.xlsx\"),\n",
    "     engine='openpyxl',\n",
    "     parse_dates=True,\n",
    "     thousands='.'\n",
    ")\n",
    "print (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f48522a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace '-' string with NaN\n",
    "df = df.replace ('-', '-1')\n",
    "\n",
    "# Also fixing ',' delimeter with '.' for float conversion\n",
    "# . is for thousands , for the last delimeter\n",
    "df['PM10 ( µg/m3 )'] = df['PM10 ( µg/m3 )'].astype(str).str.replace('.','')\n",
    "df['PM10 ( µg/m3 )'] = df['PM10 ( µg/m3 )'].astype(str).str.replace(',','.')\n",
    "\n",
    "# Casting str to float\n",
    "df['PM10 ( µg/m3 )'] = pd.to_numeric(df['PM10 ( µg/m3 )'], downcast=\"float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a1f85ef",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/deneme/opt/anaconda3/lib/python3.7/site-packages/pandas/core/ops/__init__.py:1115: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n  result = method(y)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Tarih                   0\n",
       "PM10 ( µg/m3 )          0\n",
       "SO2 ( µg/m3 )       61745\n",
       "CO ( µg/m3 )        62154\n",
       "NO2 ( µg/m3 )       63773\n",
       "NOX ( µg/m3 )       67718\n",
       "O3 ( µg/m3 )        62743\n",
       "PM 2.5 ( µg/m3 )    67638\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "# Counting number of -1 in the column\n",
    "df[df == '-1'].count () "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b29120fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling empty rows\n",
    "# https://towardsdatascience.com/7-ways-to-handle-missing-values-in-machine-learning-1a6326adf79e\n",
    "# 1- We cant just delete them because we need consistent timestamps\n",
    "# 2- If too many empty rows exists we should discard them\n",
    "# 3- Replacing missing data with mean/median\n",
    "# 3.1- This does not cover the covariance between features\n",
    "df['PM10 ( µg/m3 )'] = df['PM10 ( µg/m3 )'].replace (-1.0, df[df != -1]['PM10 ( µg/m3 )'].median ())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1dc3118f",
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0        26.1\n",
       "1        26.1\n",
       "2        26.1\n",
       "3        26.1\n",
       "4        26.1\n",
       "         ... \n",
       "81690    11.1\n",
       "81691    17.4\n",
       "81692    30.0\n",
       "81693    18.6\n",
       "81694    26.1\n",
       "Name: PM10 ( µg/m3 ), Length: 81695, dtype: float32"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "df['PM10 ( µg/m3 )']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbc0e57",
   "metadata": {},
   "source": [
    "## Town - Pollution Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e90e8f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dataframes per town\n",
    "dfAksaray = pd.read_excel(os.path.join(\"datasets\", \"pollutants\", \"aksaray.xlsx\"),engine='openpyxl',parse_dates=True,thousands='.')\n",
    "dfBesiktas = pd.read_excel(os.path.join(\"datasets\", \"pollutants\", \"besiktas.xlsx\"),engine='openpyxl',parse_dates=True,thousands='.')\n",
    "dfBuyukada = pd.read_excel(os.path.join(\"datasets\", \"pollutants\", \"buyukada.xlsx\"),engine='openpyxl',parse_dates=True,thousands='.')\n",
    "dfCatladıkapı = pd.read_excel(os.path.join(\"datasets\", \"pollutants\", \"catladıkapı.xlsx\"),engine='openpyxl',parse_dates=True,thousands='.')\n",
    "dfEsenler = pd.read_excel(os.path.join(\"datasets\", \"pollutants\", \"esenler.xlsx\"),engine='openpyxl',parse_dates=True,thousands='.')\n",
    "dfKadıkoy = pd.read_excel(os.path.join(\"datasets\", \"pollutants\", \"kadıkoy.xlsx\"),engine='openpyxl',parse_dates=True,thousands='.')\n",
    "dfKandilli = pd.read_excel(os.path.join(\"datasets\", \"pollutants\", \"kandilli.xlsx\"),engine='openpyxl',parse_dates=True,thousands='.')\n",
    "dfKartal = pd.read_excel(os.path.join(\"datasets\", \"pollutants\", \"kartal.xlsx\"),engine='openpyxl',parse_dates=True,thousands='.')\n",
    "dfMecidiyekoy = pd.read_excel(os.path.join(\"datasets\", \"pollutants\", \"mecidiyekoy.xlsx\"),engine='openpyxl',parse_dates=True,thousands='.')\n",
    "dfUmraniye = pd.read_excel(os.path.join(\"datasets\", \"pollutants\", \"umraniye.xlsx\"),engine='openpyxl',parse_dates=True,thousands='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def fixValues(df):\n",
    "    # Replace '-' string with NaN\n",
    "    df = df.replace ('-', '-1')\n",
    "\n",
    "    # Also fixing ',' delimeter with '.' for float conversion '.' is for thousands , for the last delimeter\n",
    "    # Casting str to float\n",
    "    df['PM10 ( µg/m3 )'] = df['PM10 ( µg/m3 )'].astype(str).str.replace('.','')\n",
    "    df['PM10 ( µg/m3 )'] = df['PM10 ( µg/m3 )'].astype(str).str.replace(',','.')\n",
    "    df['PM10 ( µg/m3 )'] = pd.to_numeric(df['PM10 ( µg/m3 )'], downcast=\"float\")\n",
    "    \n",
    "    df['SO2 ( µg/m3 )'] = df['SO2 ( µg/m3 )'].astype(str).str.replace('.','')\n",
    "    df['SO2 ( µg/m3 )'] = df['SO2 ( µg/m3 )'].astype(str).str.replace(',','.')\n",
    "    df['SO2 ( µg/m3 )'] = pd.to_numeric(df['SO2 ( µg/m3 )'], downcast=\"float\")\n",
    "    \n",
    "    df['CO ( µg/m3 )'] = df['CO ( µg/m3 )'].astype(str).str.replace('.','')\n",
    "    df['CO ( µg/m3 )'] = df['CO ( µg/m3 )'].astype(str).str.replace(',','.')\n",
    "    df['CO ( µg/m3 )'] = pd.to_numeric(df['CO ( µg/m3 )'], downcast=\"float\")\n",
    "    \n",
    "    df['NO2 ( µg/m3 )'] = df['NO2 ( µg/m3 )'].astype(str).str.replace('.','')\n",
    "    df['NO2 ( µg/m3 )'] = df['NO2 ( µg/m3 )'].astype(str).str.replace(',','.')\n",
    "    df['NO2 ( µg/m3 )'] = pd.to_numeric(df['NO2 ( µg/m3 )'], downcast=\"float\")\n",
    "    \n",
    "    df['NOX ( µg/m3 )'] = df['NOX ( µg/m3 )'].astype(str).str.replace('.','')\n",
    "    df['NOX ( µg/m3 )'] = df['NOX ( µg/m3 )'].astype(str).str.replace(',','.')\n",
    "    df['NOX ( µg/m3 )'] = pd.to_numeric(df['NOX ( µg/m3 )'], downcast=\"float\")\n",
    "    \n",
    "    df['O3 ( µg/m3 )'] = df['O3 ( µg/m3 )'].astype(str).str.replace('.','')\n",
    "    df['O3 ( µg/m3 )'] = df['O3 ( µg/m3 )'].astype(str).str.replace(',','.')\n",
    "    df['O3 ( µg/m3 )'] = pd.to_numeric(df['O3 ( µg/m3 )'], downcast=\"float\")\n",
    "    \n",
    "    df['PM 2.5 ( µg/m3 )'] = df['PM 2.5 ( µg/m3 )'].astype(str).str.replace('.','')\n",
    "    df['PM 2.5 ( µg/m3 )'] = df['PM 2.5 ( µg/m3 )'].astype(str).str.replace(',','.')\n",
    "    df['PM 2.5 ( µg/m3 )'] = pd.to_numeric(df['PM 2.5 ( µg/m3 )'], downcast=\"float\")\n",
    "    \n",
    "    return df\n",
    "    \n",
    "def fillEmptyRows(df):\n",
    "    # Filling empty rows\n",
    "    # https://towardsdatascience.com/7-ways-to-handle-missing-values-in-machine-learning-1a6326adf79e\n",
    "    # 1- We cant just delete them because we need consistent timestamps\n",
    "    # 2- If too many empty rows exists we should discard them\n",
    "    # 3- Replacing missing data with mean/median\n",
    "    # 3.1- This does not cover the covariance between features\n",
    "    \n",
    "    #df['PM10 ( µg/m3 )'] = df['PM10 ( µg/m3 )'].replace (-1.0, df[df != -1]['PM10 ( µg/m3 )'].median ())\n",
    "    #df['SO2 ( µg/m3 )'] = df['SO2 ( µg/m3 )'].replace (-1.0, df[df != -1]['SO2 ( µg/m3 )'].median ())\n",
    "    #df['CO ( µg/m3 )'] = df['CO ( µg/m3 )'].replace (-1.0, df[df != -1]['CO ( µg/m3 )'].median ())\n",
    "    #df['NO2 ( µg/m3 )'] = df['NO2 ( µg/m3 )'].replace (-1.0, df[df != -1]['NO2 ( µg/m3 )'].median ())\n",
    "    #df['NOX ( µg/m3 )'] = df['NOX ( µg/m3 )'].replace (-1.0, df[df != -1]['NOX ( µg/m3 )'].median ())\n",
    "    #df['O3 ( µg/m3 )'] = df['O3 ( µg/m3 )'].replace (-1.0, df[df != -1]['O3 ( µg/m3 )'].median ())\n",
    "    #df['PM 2.5 ( µg/m3 )'] = df['PM 2.5 ( µg/m3 )'].replace (-1.0, df[df != -1]['PM 2.5 ( µg/m3 )'].median ())\n",
    "    if not(df['PM10 ( µg/m3 )'][df['PM10 ( µg/m3 )']!=-1].count()>0):df['PM10 ( µg/m3 )']=0\n",
    "    if not(df['SO2 ( µg/m3 )'][df['SO2 ( µg/m3 )']!=-1].count()>0):df['SO2 ( µg/m3 )']=0\n",
    "    if not(df['CO ( µg/m3 )'][df['CO ( µg/m3 )']!=-1].count()>0):df['CO ( µg/m3 )']=0\n",
    "    if not(df['NO2 ( µg/m3 )'][df['NO2 ( µg/m3 )']!=-1].count()>0):df['NO2 ( µg/m3 )']=0\n",
    "    if not(df['NOX ( µg/m3 )'][df['NOX ( µg/m3 )']!=-1].count()>0):df['NOX ( µg/m3 )']=0\n",
    "    if not(df['O3 ( µg/m3 )'][df['O3 ( µg/m3 )']!=-1].count()>0):df['O3 ( µg/m3 )']=0\n",
    "    if not(df['PM 2.5 ( µg/m3 )'][df['PM 2.5 ( µg/m3 )']!=-1].count()>0):df['PM 2.5 ( µg/m3 )']=0\n",
    "\n",
    "    #if not(df['PM10 ( µg/m3 )'].notnull().values.any()): df['PM10 ( µg/m3 )']=0\n",
    "    #if not(df['SO2 ( µg/m3 )'].notnull().values.any()): df['SO2 ( µg/m3 )']=0\n",
    "    #if not(df['CO ( µg/m3 )'].notnull().values.any()): df['CO ( µg/m3 )']=0\n",
    "    #if not(df['NO2 ( µg/m3 )'].notnull().values.any()): df['NO2 ( µg/m3 )']=0\n",
    "    #if not(df['NOX ( µg/m3 )'].notnull().values.any()): df['NOX ( µg/m3 )']=0\n",
    "    #if not(df['O3 ( µg/m3 )'].notnull().values.any()): df['O3 ( µg/m3 )']=0\n",
    "    #if not(df['PM 2.5 ( µg/m3 )'].notnull().values.any()): df['PM 2.5 ( µg/m3 )']=0\n",
    "\n",
    "    df = fillWithSameHourValue(df, 'PM10 ( µg/m3 )')\n",
    "    df = fillWithSameHourValue(df, 'SO2 ( µg/m3 )')\n",
    "    df = fillWithSameHourValue(df, 'CO ( µg/m3 )')\n",
    "    df = fillWithSameHourValue(df, 'NO2 ( µg/m3 )')\n",
    "    df = fillWithSameHourValue(df, 'NOX ( µg/m3 )')\n",
    "    df = fillWithSameHourValue(df, 'O3 ( µg/m3 )')\n",
    "    df = fillWithSameHourValue(df, 'PM 2.5 ( µg/m3 )')\n",
    "    return df\n",
    "\n",
    "def fillWithSameHourValue(df, pollutantColumnName):\n",
    "    for x in range (df[pollutantColumnName].shape[0]):\n",
    "        if(df[pollutantColumnName].iloc[x] == -1 and x < 24):\n",
    "            df[pollutantColumnName].iloc[x] = findValue(df[pollutantColumnName], x)\n",
    "        if(df[pollutantColumnName].iloc[x] == -1 and x >= 24):\n",
    "            df[pollutantColumnName].iloc[x] = df[pollutantColumnName].iloc[x-24]\n",
    "        \n",
    "    return df\n",
    "\n",
    "def findValue(df, i):\n",
    "    if(df.shape[0]<=i):\n",
    "        return 0\n",
    "\n",
    "    if(df.iloc[i] == -1):\n",
    "        i = i+24\n",
    "        return findValue(df, i)\n",
    "    else:\n",
    "        return df.iloc[i] \n",
    "\n",
    "def preprocessingx(df):\n",
    "    df = fixValues(df)\n",
    "    df = fillEmptyRows(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e49f226e",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/deneme/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:205: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "# making preprocessing (fixing values, filling empty rows)\n",
    "dfAksaray = preprocessing(dfAksaray)\n",
    "dfBesiktas = preprocessing(dfBesiktas)\n",
    "dfBuyukada = preprocessing(dfBuyukada)\n",
    "dfCatladıkapı = preprocessing(dfCatladıkapı)\n",
    "dfEsenler = preprocessing(dfEsenler)\n",
    "dfKadıkoy = preprocessing(dfKadıkoy)\n",
    "dfKandilli = preprocessing(dfKandilli)\n",
    "dfKartal = preprocessing(dfKartal)\n",
    "dfMecidiyekoy = preprocessing(dfMecidiyekoy)\n",
    "dfUmraniye = preprocessing(dfUmraniye)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3aad4e22",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "         Aksaray   Besiktas   Buyukada  Catladıkapı    Esenler    Kadıkoy  \\\n0      42.200001  37.599998   9.600000    24.100000  28.100000  21.400000   \n1      41.799999  42.000000  12.000000    27.299999  34.200001  24.200001   \n2      44.200001  39.000000  12.800000    40.200001  33.099998  18.799999   \n3      41.700001  37.599998  13.800000    41.599998  33.799999  18.000000   \n4      49.700001  48.500000  16.400000    40.900002  36.000000  19.500000   \n...          ...        ...        ...          ...        ...        ...   \n19995  23.600000  11.100000  13.000000    13.800000  12.200000  14.400000   \n19996  25.900000  17.400000   8.700000    17.200001  18.200001  17.600000   \n19997  27.600000  30.000000  13.300000    14.600000  18.299999  24.000000   \n19998  19.700001  18.600000  30.600000    14.800000  22.000000  30.799999   \n19999  27.100000  13.200000  26.200001    16.400000  31.299999  41.200001   \n\n       Kandilli     Kartal  Mecidiyekoy   Umraniye  \n0           6.8  46.599998    73.320000  34.200001  \n1           5.3  39.700001    76.489998  38.200001  \n2          11.5  49.299999    77.769997  45.400002  \n3          13.4  47.099998    82.419998  43.599998  \n4          18.0  48.799999    82.059998  47.000000  \n...         ...        ...          ...        ...  \n19995       3.8  31.100000    47.720001  28.799999  \n19996       1.9  26.600000    41.580002  21.400000  \n19997       1.0  24.299999    51.840000  29.400000  \n19998       2.7  24.200001    53.709999  23.200001  \n19999       1.1  63.200001    56.070000  28.799999  \n\n[20000 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "# Initialize data to Dicts of series.  \n",
    "lastNItems = 20000\n",
    "columnName = 'PM10 ( µg/m3 )'\n",
    "excelName = 'datasets/training/PM10.xlsx'\n",
    "\n",
    "d = {\n",
    "    'Aksaray' : dfAksaray[columnName][-lastNItems:].tolist(),  \n",
    "    'Besiktas' : dfBesiktas[columnName][-lastNItems:].tolist(),\n",
    "    'Buyukada' : dfBuyukada[columnName][-lastNItems:].tolist(), \n",
    "    'Catladıkapı' : dfCatladıkapı[columnName][-lastNItems:].tolist(),\n",
    "    'Esenler' : dfEsenler[columnName][-lastNItems:].tolist(), \n",
    "    'Kadıkoy' : dfKadıkoy[columnName][-lastNItems:].tolist(),\n",
    "    'Kandilli' : dfKandilli[columnName][-lastNItems:].tolist(), \n",
    "    'Kartal'    : dfKartal[columnName][-lastNItems:].tolist(),\n",
    "    'Mecidiyekoy' : dfMecidiyekoy[columnName][-lastNItems:].tolist(), \n",
    "    'Umraniye'    : dfUmraniye[columnName][-lastNItems:].tolist()\n",
    "    \n",
    "}  \n",
    "  \n",
    "# creates Dataframe.  \n",
    "dframe = pd.DataFrame(d, columns = ['Aksaray', 'Besiktas','Buyukada','Catladıkapı','Esenler','Kadıkoy','Kandilli','Kartal','Mecidiyekoy','Umraniye']) \n",
    "  \n",
    "# print the data.  \n",
    "print(dframe) \n",
    "\n",
    "# export to excel\n",
    "dframe.to_excel(excelName) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e82d28",
   "metadata": {},
   "source": [
    "## Sensor Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "311e2f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import cos, asin, sqrt, pi\n",
    "\n",
    "# Distance between two coordinates taken from\n",
    "# https://stackoverflow.com/questions/27928/calculate-distance-between-two-latitude-longitude-points-haversine-formula\n",
    "def coord_distance(lat1, lon1, lat2, lon2):\n",
    "    p = pi/180\n",
    "    a = 0.5 - cos((lat2-lat1)*p)/2 + cos(lat1*p) * cos(lat2*p) * (1-cos((lon2-lon1)*p))/2\n",
    "    return 12742 * asin(sqrt(a)) #2*R*asin..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "19f12573",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "          İlçe    Enlem   Boylam\n0      aksaray  41.0244  29.0997\n1     besiktas  41.0520  29.0094\n2     buyukada  40.8521  29.1180\n3  catladıkapı  41.0023  28.9751\n4      esenler  41.0368  28.8880\n5      kadıkoy  40.9908  29.0333\n6     kandilli  41.0624  29.0582\n7       kartal  40.9110  29.1830\n8  mecidiyekoy  41.0659  28.9944\n9     umraniye  41.0126  29.1618\n(10, 3)\n"
     ]
    }
   ],
   "source": [
    "sensor_l = pd.read_excel(\n",
    "     os.path.join(\"datasets/adjacency/sensor_locations.xlsx\"),\n",
    "     engine='openpyxl',\n",
    "     parse_dates=True,\n",
    ")\n",
    "n_sensors = sensor_l.shape[0]\n",
    "print (sensor_l)\n",
    "print (sensor_l.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0326e776",
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[1.        , 0.72246006, 0.34720973, 0.63525996, 0.39507831,\n",
       "        0.77216223, 0.81407726, 0.51027434, 0.66159891, 0.81752721],\n",
       "       [0.72246006, 1.        , 0.18399078, 0.78839024, 0.64948686,\n",
       "        0.75905202, 0.85558757, 0.27301488, 0.93232307, 0.54105276],\n",
       "       [0.34720973, 0.18399078, 1.        , 0.30142131, 0.04239443,\n",
       "        0.42311837, 0.18768574, 0.71030258, 0.11898075, 0.38111595],\n",
       "       [0.63525996, 0.78839024, 0.30142131, 1.        , 0.71969965,\n",
       "        0.828519  , 0.67203794, 0.31409166, 0.75359924, 0.46650847],\n",
       "       [0.39507831, 0.64948686, 0.04239443, 0.71969965, 1.        ,\n",
       "        0.5509857 , 0.50571456, 0.03396331, 0.67766267, 0.21457354],\n",
       "       [0.77216223, 0.75905202, 0.42311837, 0.828519  , 0.5509857 ,\n",
       "        1.        , 0.72044807, 0.47736705, 0.6954975 , 0.62461969],\n",
       "       [0.81407726, 0.85558757, 0.18768574, 0.67203794, 0.50571456,\n",
       "        0.72044807, 1.        , 0.32657829, 0.8178543 , 0.65005373],\n",
       "       [0.51027434, 0.27301488, 0.71030258, 0.31409166, 0.03396331,\n",
       "        0.47736705, 0.32657829, 1.        , 0.20547643, 0.61156863],\n",
       "       [0.66159891, 0.93232307, 0.11898075, 0.75359924, 0.67766267,\n",
       "        0.6954975 , 0.8178543 , 0.20547643, 1.        , 0.48241643],\n",
       "       [0.81752721, 0.54105276, 0.38111595, 0.46650847, 0.21457354,\n",
       "        0.62461969, 0.65005373, 0.61156863, 0.48241643, 1.        ]])"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "# Preparing adjacency matrix for the sensor nodes\n",
    "distance_matrix = np.zeros ((n_sensors, n_sensors))\n",
    "\n",
    "# Create distance matrix from each sensor to other ones\n",
    "# For each sensor\n",
    "ix = 0\n",
    "for sensor in sensor_l['İlçe']:\n",
    "    s_lat = sensor_l[sensor_l['İlçe'] == sensor].values[0][1]\n",
    "    s_lon = sensor_l[sensor_l['İlçe'] == sensor].values[0][2]\n",
    "    # Look at other sensors\n",
    "    o_ix = 0\n",
    "    for o_sensor in sensor_l['İlçe']:\n",
    "        o_lat = sensor_l[sensor_l['İlçe'] == o_sensor].values[0][1] \n",
    "        o_lon = sensor_l[sensor_l['İlçe'] == o_sensor].values[0][2] \n",
    "        # Calculate the distance\n",
    "        distance = coord_distance (s_lat, s_lon, o_lat, o_lon)\n",
    "        # Update the distance matrix\n",
    "        distance_matrix [ix][o_ix] = distance\n",
    "        #\n",
    "        o_ix += 1\n",
    "    ix += 1\n",
    "    \n",
    "# Take the absolute of the difference between all values and the max value\n",
    "# Then divide it by the max value to get the weighted adjacency matrix\n",
    "# Add 1 to the max value so that the weights will never be lost\n",
    "max_val = np.max (distance_matrix) + 1\n",
    "distance_matrix = (max_val - distance_matrix)/max_val\n",
    "distance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "74783033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export to excel\n",
    "workbook = xlsxwriter.Workbook('datasets/training/sensor_dist_adj.xlsx')\n",
    "worksheet = workbook.add_worksheet()\n",
    "\n",
    "row = 0\n",
    "\n",
    "for col, data in enumerate(distance_matrix):\n",
    "    worksheet.write_column(row, col, data)\n",
    "\n",
    "workbook.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa4e520",
   "metadata": {},
   "source": [
    "## Population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "54aa56ce",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "     Yıl           İlçe  İlçe Nüfusu  Erkek Nüfusu  Kadın Nüfusu  \\\n0   2020         Adalar        16033          8358          7675   \n1   2020     Arnavutköy       296709        152668        144041   \n2   2020       Ataşehir       422594        207697        214897   \n3   2020        Avcılar       436897        219428        217469   \n4   2020       Bağcılar       737206        374475        362731   \n5   2020   Bahçelievler       592371        298341        294030   \n6   2020       Bakırköy       226229        105741        120488   \n7   2020     Başakşehir       469924        236589        233335   \n8   2020     Bayrampaşa       269950        135664        134286   \n9   2020       Beşiktaş       176513         80715         95798   \n10  2020         Beykoz       246110        122425        123685   \n11  2020     Beylikdüzü       365572        178615        186957   \n12  2020        Beyoğlu       226396        116771        109625   \n13  2020   Büyükçekmece       257362        127461        129901   \n14  2020        Çatalca        74975         38447         36528   \n15  2020       Çekmeköy       273658        136842        136816   \n16  2020        Esenler       446276        229277        216999   \n17  2020       Esenyurt       957398        491843        465555   \n18  2020     Eyüpsultan       405845        203218        202627   \n19  2020          Fatih       396594        199149        197445   \n20  2020  Gaziosmanpaşa       487778        244783        242995   \n21  2020       Güngören       280299        141446        138853   \n22  2020        Kadıköy       481983        218424        263559   \n23  2020      Kağıthane       442415        223447        218968   \n24  2020         Kartal       474514        234618        239896   \n25  2020   Küçükçekmece       789633        395884        393749   \n26  2020        Maltepe       515021        256869        258152   \n27  2020         Pendik       726481        367107        359374   \n28  2020     Sancaktepe       456861        231744        225117   \n29  2020        Sarıyer       335298        165405        169893   \n30  2020        Silivri       200215        113154         87061   \n31  2020    Sultanbeyli       343318        176121        167197   \n32  2020     Sultangazi       537488        274044        263444   \n33  2020           Şile        37904         19709         18195   \n34  2020          Şişli       266793        129931        136862   \n35  2020          Tuzla       273608        139481        134127   \n36  2020       Ümraniye       713803        358075        355728   \n37  2020        Üsküdar       520771        253680        267091   \n38  2020    Zeytinburnu       283657        143190        140467   \n\n    Nüfus Yüzdesi  \n0          0.0010  \n1          0.0192  \n2          0.0273  \n3          0.0283  \n4          0.0477  \n5          0.0383  \n6          0.0146  \n7          0.0304  \n8          0.0175  \n9          0.0114  \n10         0.0159  \n11         0.0236  \n12         0.0146  \n13         0.0166  \n14         0.0048  \n15         0.0177  \n16         0.0289  \n17         0.0619  \n18         0.0262  \n19         0.0256  \n20         0.0315  \n21         0.0181  \n22         0.0312  \n23         0.0286  \n24         0.0307  \n25         0.0511  \n26         0.0333  \n27         0.0470  \n28         0.0295  \n29         0.0217  \n30         0.0129  \n31         0.0222  \n32         0.0348  \n33         0.0025  \n34         0.0173  \n35         0.0177  \n36         0.0462  \n37         0.0337  \n38         0.0183  \n(39, 6)\n"
     ]
    }
   ],
   "source": [
    "sensor_l = pd.read_excel(\n",
    "     os.path.join(\"datasets/adjacency/population.xlsx\"),\n",
    "     engine='openpyxl',\n",
    "     parse_dates=True,\n",
    ")\n",
    "n_sensors = sensor_l.shape[0]\n",
    "print (sensor_l)\n",
    "print (sensor_l.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb114c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python374jvsc74a57bd0fc9c1e1bd2f958361b34454cff99611c970e5cf7b1a4a61c9cc910440db53ba1",
   "display_name": "Python 3.7.4 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "metadata": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}