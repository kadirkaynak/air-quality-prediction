{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import locale\n",
    "from locale import atof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Tarih PM10 ( µg/m3 ) SO2 ( µg/m3 ) CO ( µg/m3 )  \\\n",
      "0     2012-01-01 01:00:56              -             -            -   \n",
      "1     2012-01-01 02:00:56              -             -            -   \n",
      "2     2012-01-01 03:00:56              -             -            -   \n",
      "3     2012-01-01 04:00:56              -             -            -   \n",
      "4     2012-01-01 05:00:56              -             -            -   \n",
      "...                   ...            ...           ...          ...   \n",
      "81690 2021-04-26 19:00:56          11,10          1,00       296,70   \n",
      "81691 2021-04-26 20:00:56          17,40          0,80       254,10   \n",
      "81692 2021-04-26 21:00:56          30,00          0,70       180,00   \n",
      "81693 2021-04-26 22:00:56          18,60          1,00       399,00   \n",
      "81694 2021-04-26 23:00:56              -          1,10       446,60   \n",
      "\n",
      "      NO2 ( µg/m3 ) NOX ( µg/m3 ) O3 ( µg/m3 ) PM 2.5 ( µg/m3 )  \n",
      "0                 -             -            -                -  \n",
      "1                 -             -            -                -  \n",
      "2                 -             -            -                -  \n",
      "3                 -             -            -                -  \n",
      "4                 -             -            -                -  \n",
      "...             ...           ...          ...              ...  \n",
      "81690         15,90             -        31,60                -  \n",
      "81691         15,80             -        34,40                -  \n",
      "81692         18,90             -        31,70                -  \n",
      "81693         23,30             -        17,10                -  \n",
      "81694         22,10             -        22,20                -  \n",
      "\n",
      "[81695 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel(\n",
    "     os.path.join(\"datasets\", \"besiktas.xlsx\"),\n",
    "     engine='openpyxl',\n",
    "     parse_dates=True,\n",
    "     thousands='.'\n",
    ")\n",
    "print (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace '-' string with NaN\n",
    "df = df.replace ('-', '-1')\n",
    "\n",
    "# Also fixing ',' delimeter with '.' for float conversion\n",
    "# . is for thousands , for the last delimeter\n",
    "df['PM10 ( µg/m3 )'] = df['PM10 ( µg/m3 )'].astype(str).str.replace('.','')\n",
    "df['PM10 ( µg/m3 )'] = df['PM10 ( µg/m3 )'].astype(str).str.replace(',','.')\n",
    "\n",
    "# Casting str to float\n",
    "df['PM10 ( µg/m3 )'] = pd.to_numeric(df['PM10 ( µg/m3 )'], downcast=\"float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/deneme/opt/anaconda3/lib/python3.7/site-packages/pandas/core/ops/__init__.py:1115: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  result = method(y)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Tarih                   0\n",
       "PM10 ( µg/m3 )          0\n",
       "SO2 ( µg/m3 )       61745\n",
       "CO ( µg/m3 )        62154\n",
       "NO2 ( µg/m3 )       63773\n",
       "NOX ( µg/m3 )       67718\n",
       "O3 ( µg/m3 )        62743\n",
       "PM 2.5 ( µg/m3 )    67638\n",
       "dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Counting number of -1 in the column\n",
    "df[df == '-1'].count () "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling empty rows\n",
    "# https://towardsdatascience.com/7-ways-to-handle-missing-values-in-machine-learning-1a6326adf79e\n",
    "# 1- We cant just delete them because we need consistent timestamps\n",
    "# 2- If too many empty rows exists we should discard them\n",
    "# 3- Replacing missing data with mean/median\n",
    "# 3.1- This does not cover the covariance between features\n",
    "df['PM10 ( µg/m3 )'] = df['PM10 ( µg/m3 )'].replace (-1.0, df[df != -1]['PM10 ( µg/m3 )'].median ())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        26.1\n",
       "1        26.1\n",
       "2        26.1\n",
       "3        26.1\n",
       "4        26.1\n",
       "         ... \n",
       "81690    11.1\n",
       "81691    17.4\n",
       "81692    30.0\n",
       "81693    18.6\n",
       "81694    26.1\n",
       "Name: PM10 ( µg/m3 ), Length: 81695, dtype: float32"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['PM10 ( µg/m3 )']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Town - Pollution Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixValues(df):\n",
    "    # Replace '-' string with NaN\n",
    "    df = df.replace ('-', '-1')\n",
    "\n",
    "    # Also fixing ',' delimeter with '.' for float conversion '.' is for thousands , for the last delimeter\n",
    "    # Casting str to float\n",
    "    df['PM10 ( µg/m3 )'] = df['PM10 ( µg/m3 )'].astype(str).str.replace('.','')\n",
    "    df['PM10 ( µg/m3 )'] = df['PM10 ( µg/m3 )'].astype(str).str.replace(',','.')\n",
    "    df['PM10 ( µg/m3 )'] = pd.to_numeric(df['PM10 ( µg/m3 )'], downcast=\"float\")\n",
    "    \n",
    "    df['SO2 ( µg/m3 )'] = df['SO2 ( µg/m3 )'].astype(str).str.replace('.','')\n",
    "    df['SO2 ( µg/m3 )'] = df['SO2 ( µg/m3 )'].astype(str).str.replace(',','.')\n",
    "    df['SO2 ( µg/m3 )'] = pd.to_numeric(df['SO2 ( µg/m3 )'], downcast=\"float\")\n",
    "    \n",
    "    df['CO ( µg/m3 )'] = df['CO ( µg/m3 )'].astype(str).str.replace('.','')\n",
    "    df['CO ( µg/m3 )'] = df['CO ( µg/m3 )'].astype(str).str.replace(',','.')\n",
    "    df['CO ( µg/m3 )'] = pd.to_numeric(df['CO ( µg/m3 )'], downcast=\"float\")\n",
    "    \n",
    "    df['NO2 ( µg/m3 )'] = df['NO2 ( µg/m3 )'].astype(str).str.replace('.','')\n",
    "    df['NO2 ( µg/m3 )'] = df['NO2 ( µg/m3 )'].astype(str).str.replace(',','.')\n",
    "    df['NO2 ( µg/m3 )'] = pd.to_numeric(df['NO2 ( µg/m3 )'], downcast=\"float\")\n",
    "    \n",
    "    df['NOX ( µg/m3 )'] = df['NOX ( µg/m3 )'].astype(str).str.replace('.','')\n",
    "    df['NOX ( µg/m3 )'] = df['NOX ( µg/m3 )'].astype(str).str.replace(',','.')\n",
    "    df['NOX ( µg/m3 )'] = pd.to_numeric(df['NOX ( µg/m3 )'], downcast=\"float\")\n",
    "    \n",
    "    df['O3 ( µg/m3 )'] = df['O3 ( µg/m3 )'].astype(str).str.replace('.','')\n",
    "    df['O3 ( µg/m3 )'] = df['O3 ( µg/m3 )'].astype(str).str.replace(',','.')\n",
    "    df['O3 ( µg/m3 )'] = pd.to_numeric(df['O3 ( µg/m3 )'], downcast=\"float\")\n",
    "    \n",
    "    df['PM 2.5 ( µg/m3 )'] = df['PM 2.5 ( µg/m3 )'].astype(str).str.replace('.','')\n",
    "    df['PM 2.5 ( µg/m3 )'] = df['PM 2.5 ( µg/m3 )'].astype(str).str.replace(',','.')\n",
    "    df['PM 2.5 ( µg/m3 )'] = pd.to_numeric(df['PM 2.5 ( µg/m3 )'], downcast=\"float\")\n",
    "    \n",
    "    return df\n",
    "    \n",
    "def fillEmptyRows(df):\n",
    "    # Filling empty rows\n",
    "    # https://towardsdatascience.com/7-ways-to-handle-missing-values-in-machine-learning-1a6326adf79e\n",
    "    # 1- We cant just delete them because we need consistent timestamps\n",
    "    # 2- If too many empty rows exists we should discard them\n",
    "    # 3- Replacing missing data with mean/median\n",
    "    # 3.1- This does not cover the covariance between features\n",
    "    df['PM10 ( µg/m3 )'] = df['PM10 ( µg/m3 )'].replace (-1.0, df[df != -1]['PM10 ( µg/m3 )'].median ())\n",
    "    df['SO2 ( µg/m3 )'] = df['SO2 ( µg/m3 )'].replace (-1.0, df[df != -1]['SO2 ( µg/m3 )'].median ())\n",
    "    df['CO ( µg/m3 )'] = df['CO ( µg/m3 )'].replace (-1.0, df[df != -1]['CO ( µg/m3 )'].median ())\n",
    "    df['NO2 ( µg/m3 )'] = df['NO2 ( µg/m3 )'].replace (-1.0, df[df != -1]['NO2 ( µg/m3 )'].median ())\n",
    "    df['NOX ( µg/m3 )'] = df['NOX ( µg/m3 )'].replace (-1.0, df[df != -1]['NOX ( µg/m3 )'].median ())\n",
    "    df['O3 ( µg/m3 )'] = df['O3 ( µg/m3 )'].replace (-1.0, df[df != -1]['O3 ( µg/m3 )'].median ())\n",
    "    df['PM 2.5 ( µg/m3 )'] = df['PM 2.5 ( µg/m3 )'].replace (-1.0, df[df != -1]['PM 2.5 ( µg/m3 )'].median ())\n",
    "    \n",
    "    return df\n",
    "\n",
    "def preprocessing(df):\n",
    "    df = fixValues(df)\n",
    "    df = fillEmptyRows(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dataframes per town\n",
    "dfAksaray = pd.read_excel(os.path.join(\"datasets\", \"aksaray.xlsx\"),engine='openpyxl',parse_dates=True,thousands='.')\n",
    "dfBesiktas = pd.read_excel(os.path.join(\"datasets\", \"besiktas.xlsx\"),engine='openpyxl',parse_dates=True,thousands='.')\n",
    "dfBuyukada = pd.read_excel(os.path.join(\"datasets\", \"buyukada.xlsx\"),engine='openpyxl',parse_dates=True,thousands='.')\n",
    "dfCatladıkapı = pd.read_excel(os.path.join(\"datasets\", \"catladıkapı.xlsx\"),engine='openpyxl',parse_dates=True,thousands='.')\n",
    "dfEsenler = pd.read_excel(os.path.join(\"datasets\", \"esenler.xlsx\"),engine='openpyxl',parse_dates=True,thousands='.')\n",
    "dfKadıkoy = pd.read_excel(os.path.join(\"datasets\", \"kadıkoy.xlsx\"),engine='openpyxl',parse_dates=True,thousands='.')\n",
    "dfKandilli = pd.read_excel(os.path.join(\"datasets\", \"kandilli.xlsx\"),engine='openpyxl',parse_dates=True,thousands='.')\n",
    "dfKartal = pd.read_excel(os.path.join(\"datasets\", \"kartal.xlsx\"),engine='openpyxl',parse_dates=True,thousands='.')\n",
    "dfMecidiyekoy = pd.read_excel(os.path.join(\"datasets\", \"mecidiyekoy.xlsx\"),engine='openpyxl',parse_dates=True,thousands='.')\n",
    "dfUmraniye = pd.read_excel(os.path.join(\"datasets\", \"umraniye.xlsx\"),engine='openpyxl',parse_dates=True,thousands='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making preprocessing (fixing values, filling empty rows)\n",
    "dfAksaray = preprocessing(dfAksaray)\n",
    "dfBesiktas = preprocessing(dfBesiktas)\n",
    "dfBuyukada = preprocessing(dfBuyukada)\n",
    "dfCatladıkapı = preprocessing(dfCatladıkapı)\n",
    "dfEsenler = preprocessing(dfEsenler)\n",
    "dfKadıkoy = preprocessing(dfKadıkoy)\n",
    "dfKandilli = preprocessing(dfKandilli)\n",
    "dfKartal = preprocessing(dfKartal)\n",
    "dfMecidiyekoy = preprocessing(dfMecidiyekoy)\n",
    "dfUmraniye = preprocessing(dfUmraniye)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Aksaray   Besiktas   Buyukada  Catladıkapı  Esenler    Kadıkoy  \\\n",
      "0      19.700001   9.500000  24.200001    26.000000      0.0  10.700000   \n",
      "1      20.400000  10.800000  22.100000    16.000000      0.0  10.500000   \n",
      "2      16.000000   9.600000  19.299999     9.100000      0.0   9.200000   \n",
      "3      11.600000   4.100000   3.700000     7.900000      0.0   7.600000   \n",
      "4      13.500000   4.400000  10.700000     4.800000      0.0  10.100000   \n",
      "...          ...        ...        ...          ...      ...        ...   \n",
      "19995   3.800000  31.600000   6.800000    32.799999      0.0  22.900000   \n",
      "19996   3.200000  34.400002   9.400000    12.600000      0.0  17.799999   \n",
      "19997   2.900000  31.700001   9.000000    16.600000      0.0  18.400000   \n",
      "19998   2.700000  17.100000   4.400000    12.300000      0.0   8.000000   \n",
      "19999   2.700000  22.200001   3.300000     7.500000      0.0   4.600000   \n",
      "\n",
      "       Kandilli     Kartal  Mecidiyekoy   Umraniye  \n",
      "0           9.0  24.799999          NaN  33.799999  \n",
      "1           5.6  24.799999          NaN  29.400000  \n",
      "2           3.3  24.799999          NaN  22.400000  \n",
      "3           2.7  24.799999          NaN   9.500000  \n",
      "4          15.4  24.799999          NaN   1.800000  \n",
      "...         ...        ...          ...        ...  \n",
      "19995       5.5  61.599998          NaN  21.799999  \n",
      "19996       5.1  32.099998          NaN  22.100000  \n",
      "19997       4.7  15.400000          NaN  14.800000  \n",
      "19998       3.4  17.500000          NaN  13.800000  \n",
      "19999       2.3   3.600000          NaN  11.800000  \n",
      "\n",
      "[20000 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "# Initialize data to Dicts of series.  \n",
    "lastNItems = 20000\n",
    "columnName = 'O3 ( µg/m3 )'\n",
    "excelName = 'O3.xlsx'\n",
    "\n",
    "d = {\n",
    "    'Aksaray' : dfAksaray[columnName][-lastNItems:].tolist(),  \n",
    "    'Besiktas' : dfBesiktas[columnName][-lastNItems:].tolist(),\n",
    "    'Buyukada' : dfBuyukada[columnName][-lastNItems:].tolist(), \n",
    "    'Catladıkapı' : dfCatladıkapı[columnName][-lastNItems:].tolist(),\n",
    "    'Esenler' : dfEsenler[columnName][-lastNItems:].tolist(), \n",
    "    'Kadıkoy' : dfKadıkoy[columnName][-lastNItems:].tolist(),\n",
    "    'Kandilli' : dfKandilli[columnName][-lastNItems:].tolist(), \n",
    "    'Kartal'    : dfKartal[columnName][-lastNItems:].tolist(),\n",
    "    'Mecidiyekoy' : dfMecidiyekoy[columnName][-lastNItems:].tolist(), \n",
    "    'Umraniye'    : dfUmraniye[columnName][-lastNItems:].tolist()\n",
    "    \n",
    "}  \n",
    "  \n",
    "# creates Dataframe.  \n",
    "dframe = pd.DataFrame(d, columns = ['Aksaray', 'Besiktas','Buyukada','Catladıkapı','Esenler','Kadıkoy','Kandilli','Kartal','Mecidiyekoy','Umraniye']) \n",
    "  \n",
    "# print the data.  \n",
    "print(dframe) \n",
    "\n",
    "# export to excel\n",
    "#dframe.to_excel(excelName) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sensor Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import cos, asin, sqrt, pi\n",
    "\n",
    "# Distance between two coordinates taken from\n",
    "# https://stackoverflow.com/questions/27928/calculate-distance-between-two-latitude-longitude-points-haversine-formula\n",
    "def coord_distance(lat1, lon1, lat2, lon2):\n",
    "    p = pi/180\n",
    "    a = 0.5 - cos((lat2-lat1)*p)/2 + cos(lat1*p) * cos(lat2*p) * (1-cos((lon2-lon1)*p))/2\n",
    "    return 12742 * asin(sqrt(a)) #2*R*asin..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          İlçe    Enlem   Boylam\n",
      "0      aksaray  41.0244  29.0997\n",
      "1     besiktas  41.0520  29.0094\n",
      "2     buyukada  40.8521  29.1180\n",
      "3  catladıkapı  41.0023  28.9751\n",
      "4      esenler  41.0368  28.8880\n",
      "5      kadıkoy  40.9908  29.0333\n",
      "6     kandilli  41.0624  29.0582\n",
      "7       kartal  40.9110  29.1830\n",
      "8  mecidiyekoy  41.0659  28.9944\n",
      "9     umraniye  41.0126  29.1618\n",
      "(10, 3)\n"
     ]
    }
   ],
   "source": [
    "sensor_l = pd.read_excel(\n",
    "     os.path.join(\"sensor_locations.xlsx\"),\n",
    "     engine='openpyxl',\n",
    "     parse_dates=True,\n",
    ")\n",
    "n_sensors = sensor_l.shape[0]\n",
    "print (sensor_l)\n",
    "print (sensor_l.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.72246006, 0.34720973, 0.63525996, 0.39507831,\n",
       "        0.77216223, 0.81407726, 0.51027434, 0.66159891, 0.81752721],\n",
       "       [0.72246006, 1.        , 0.18399078, 0.78839024, 0.64948686,\n",
       "        0.75905202, 0.85558757, 0.27301488, 0.93232307, 0.54105276],\n",
       "       [0.34720973, 0.18399078, 1.        , 0.30142131, 0.04239443,\n",
       "        0.42311837, 0.18768574, 0.71030258, 0.11898075, 0.38111595],\n",
       "       [0.63525996, 0.78839024, 0.30142131, 1.        , 0.71969965,\n",
       "        0.828519  , 0.67203794, 0.31409166, 0.75359924, 0.46650847],\n",
       "       [0.39507831, 0.64948686, 0.04239443, 0.71969965, 1.        ,\n",
       "        0.5509857 , 0.50571456, 0.03396331, 0.67766267, 0.21457354],\n",
       "       [0.77216223, 0.75905202, 0.42311837, 0.828519  , 0.5509857 ,\n",
       "        1.        , 0.72044807, 0.47736705, 0.6954975 , 0.62461969],\n",
       "       [0.81407726, 0.85558757, 0.18768574, 0.67203794, 0.50571456,\n",
       "        0.72044807, 1.        , 0.32657829, 0.8178543 , 0.65005373],\n",
       "       [0.51027434, 0.27301488, 0.71030258, 0.31409166, 0.03396331,\n",
       "        0.47736705, 0.32657829, 1.        , 0.20547643, 0.61156863],\n",
       "       [0.66159891, 0.93232307, 0.11898075, 0.75359924, 0.67766267,\n",
       "        0.6954975 , 0.8178543 , 0.20547643, 1.        , 0.48241643],\n",
       "       [0.81752721, 0.54105276, 0.38111595, 0.46650847, 0.21457354,\n",
       "        0.62461969, 0.65005373, 0.61156863, 0.48241643, 1.        ]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preparing adjacency matrix for the sensor nodes\n",
    "distance_matrix = np.zeros ((n_sensors, n_sensors))\n",
    "\n",
    "# Create distance matrix from each sensor to other ones\n",
    "# For each sensor\n",
    "ix = 0\n",
    "for sensor in sensor_l['İlçe']:\n",
    "    s_lat = sensor_l[sensor_l['İlçe'] == sensor].values[0][1]\n",
    "    s_lon = sensor_l[sensor_l['İlçe'] == sensor].values[0][2]\n",
    "    # Look at other sensors\n",
    "    o_ix = 0\n",
    "    for o_sensor in sensor_l['İlçe']:\n",
    "        o_lat = sensor_l[sensor_l['İlçe'] == o_sensor].values[0][1] \n",
    "        o_lon = sensor_l[sensor_l['İlçe'] == o_sensor].values[0][2] \n",
    "        # Calculate the distance\n",
    "        distance = coord_distance (s_lat, s_lon, o_lat, o_lon)\n",
    "        # Update the distance matrix\n",
    "        distance_matrix [ix][o_ix] = distance\n",
    "        #\n",
    "        o_ix += 1\n",
    "    ix += 1\n",
    "    \n",
    "# Take the absolute of the difference between all values and the max value\n",
    "# Then divide it by the max value to get the weighted adjacency matrix\n",
    "# Add 1 to the max value so that the weights will never be lost\n",
    "max_val = np.max (distance_matrix) + 1\n",
    "distance_matrix = (max_val - distance_matrix)/max_val\n",
    "distance_matrix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
