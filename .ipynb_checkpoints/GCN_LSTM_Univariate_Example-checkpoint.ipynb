{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Any number of GCN and LSTM layers can be added\n",
    "# Dropout and dense layers decrease the over-fitting problem\n",
    "# TODO: What can we change?\n",
    "# Method here is used for univariate (single-value) scalars\n",
    "# https://stellargraph.readthedocs.io/en/stable/demos/time-series/gcn-lstm-time-series.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-7b29ad8d079c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlines\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmlines\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "# All necessary imports here\n",
    "import os\n",
    "import sys\n",
    "import urllib.request\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential, Model\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Input\n",
    "\n",
    "import stellargraph as sg\n",
    "\n",
    "from stellargraph.layer import GCN_LSTM\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Datasets\n",
    "# A N by N adjacency matrix, which describes the distance relationship between the N sensors,\n",
    "# A N by T feature matrix, which describes the (f_1, .., f_T) speed records over T timesteps \n",
    "# for the N sensors.\n",
    "dataset = sg.datasets.METR_LA()\n",
    "speed_data, sensor_dist_adj = dataset.load()\n",
    "num_nodes, time_len = speed_data.shape\n",
    "print(\"No. of sensors:\", num_nodes, \"\\nNo of timesteps:\", time_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speed_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train - Test split\n",
    "train_rate = 0.8\n",
    "def train_test_split(data, train_portion):\n",
    "    time_len = data.shape[1]\n",
    "    train_size = int(time_len * train_portion)\n",
    "    train_data = np.array(data.iloc[:, :train_size])\n",
    "    test_data = np.array(data.iloc[:, train_size:])\n",
    "    return train_data, test_data\n",
    "\n",
    "# Scaling\n",
    "def scale_data(train_data, test_data):\n",
    "    max_speed = train_data.max()\n",
    "    min_speed = train_data.min()\n",
    "    train_scaled = (train_data - min_speed) / (max_speed - min_speed)\n",
    "    test_scaled = (test_data - min_speed) / (max_speed - min_speed)\n",
    "    return train_scaled, test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(speed_data, train_rate)\n",
    "print(\"Train data: \", train_data.shape)\n",
    "print(\"Test data: \", test_data.shape)\n",
    "train_scaled, test_scaled = scale_data(train_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This value represents the past feature window size\n",
    "seq_len = 10\n",
    "# This value represents how far ahead we want to predict\n",
    "pre_len = 12\n",
    "# Data for LSTM is prepared using the Sliding Window approach\n",
    "# Sliding windows are applied for each sensor\n",
    "def sequence_data_preparation(seq_len, pre_len, train_data, test_data):\n",
    "    trainX, trainY, testX, testY = [], [], [], []\n",
    "\n",
    "    for i in range(train_data.shape[1] - int(seq_len + pre_len - 1)):\n",
    "        a = train_data[:, i : i + seq_len + pre_len]\n",
    "        trainX.append(a[:, :seq_len])\n",
    "        trainY.append(a[:, -1])\n",
    "\n",
    "    for i in range(test_data.shape[1] - int(seq_len + pre_len - 1)):\n",
    "        b = test_data[:, i : i + seq_len + pre_len]\n",
    "        testX.append(b[:, :seq_len])\n",
    "        testY.append(b[:, -1])\n",
    "\n",
    "    trainX = np.array(trainX)\n",
    "    trainY = np.array(trainY)\n",
    "    testX = np.array(testX)\n",
    "    testY = np.array(testY)\n",
    "\n",
    "    return trainX, trainY, testX, testY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We expect to see features of seq_len window size for each sensor \n",
    "# and labels as the pre_len ahead output\n",
    "trainX, trainY, testX, testY = sequence_data_preparation(\n",
    "    seq_len, pre_len, train_scaled, test_scaled\n",
    ")\n",
    "print(trainX.shape)\n",
    "print(trainY.shape)\n",
    "print(testX.shape)\n",
    "print(testY.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the GCN LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GCN and LSTM Model\n",
    "gc_layer_sizes = [16, 10]\n",
    "gc_activations = [\"relu\", \"relu\"]\n",
    "lstm_layer_sizes = [200, 200]\n",
    "lstm_activations = [\"tanh\", \"tanh\"]\n",
    "\n",
    "gcn_lstm = GCN_LSTM(\n",
    "    seq_len=seq_len,\n",
    "    adj=sensor_dist_adj,\n",
    "    gc_layer_sizes=gc_layer_sizes,\n",
    "    gc_activations=gc_activations,\n",
    "    lstm_layer_sizes=lstm_layer_sizes,\n",
    "    lstm_activations=lstm_activations,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_input, x_output = gcn_lstm.in_out_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=x_input, outputs=x_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = \"adam\"\n",
    "loss = \"mae\"\n",
    "metrics = [\"mse\"]\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "n_epochs = 100\n",
    "batch_size = 60\n",
    "shuffle = True\n",
    "verbose = 0\n",
    "\n",
    "history = model.fit(\n",
    "    trainX,\n",
    "    trainY,\n",
    "    epochs=n_epochs,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=shuffle,\n",
    "    verbose=verbose,\n",
    "    validation_data=(testX, testY),\n",
    ")\n",
    "\n",
    "print(\"Execution time: %s seconds\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"Train loss: \",\n",
    "    history.history[\"loss\"][-1],\n",
    "    \"\\nTest loss:\",\n",
    "    history.history[\"val_loss\"][-1],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg.utils.plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actual prediction\n",
    "ythat = model.predict(trainX)\n",
    "yhat = model.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to rescale the predictions because we applied normalization in the first place\n",
    "## Rescale values\n",
    "max_speed = train_data.max()\n",
    "min_speed = train_data.min()\n",
    "\n",
    "## actual train and test values\n",
    "train_rescref = np.array(trainY * max_speed)\n",
    "test_rescref = np.array(testY * max_speed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Rescale model predicted values\n",
    "train_rescpred = np.array((ythat) * max_speed)\n",
    "test_rescpred = np.array((yhat) * max_speed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measuring Performance\n",
    "## Naive prediction benchmark (using previous observed value)\n",
    "\n",
    "testnpred = np.array(testX)[\n",
    "    :, :, -1\n",
    "]  # picking the last speed of the 10 sequence for each segment in each sample\n",
    "testnpredc = (testnpred) * max_speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Performance measures\n",
    "\n",
    "seg_mael = []\n",
    "seg_masel = []\n",
    "seg_nmael = []\n",
    "\n",
    "for j in range(testX.shape[-1]):\n",
    "\n",
    "    seg_mael.append(\n",
    "        np.mean(np.abs(test_rescref.T[j] - test_rescpred.T[j]))\n",
    "    )  # Mean Absolute Error for NN\n",
    "    seg_nmael.append(\n",
    "        np.mean(np.abs(test_rescref.T[j] - testnpredc.T[j]))\n",
    "    )  # Mean Absolute Error for naive prediction\n",
    "    if seg_nmael[-1] != 0:\n",
    "        seg_masel.append(\n",
    "            seg_mael[-1] / seg_nmael[-1]\n",
    "        )  # Ratio of the two: Mean Absolute Scaled Error\n",
    "    else:\n",
    "        seg_masel.append(np.NaN)\n",
    "\n",
    "print(\"Total (ave) MAE for NN: \" + str(np.mean(np.array(seg_mael))))\n",
    "print(\"Total (ave) MAE for naive prediction: \" + str(np.mean(np.array(seg_nmael))))\n",
    "print(\n",
    "    \"Total (ave) MASE for per-segment NN/naive MAE: \"\n",
    "    + str(np.nanmean(np.array(seg_masel)))\n",
    ")\n",
    "print(\n",
    "    \"...note that MASE<1 (for a given segment) means that the NN prediction is better than the naive prediction.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot violin plot of MAE for naive and NN predictions\n",
    "fig, ax = plt.subplots()\n",
    "# xl = minsl\n",
    "\n",
    "ax.violinplot(\n",
    "    list(seg_mael), showmeans=True, showmedians=False, showextrema=False, widths=1.0\n",
    ")\n",
    "\n",
    "ax.violinplot(\n",
    "    list(seg_nmael), showmeans=True, showmedians=False, showextrema=False, widths=1.0\n",
    ")\n",
    "\n",
    "line1 = mlines.Line2D([], [], label=\"NN\")\n",
    "line2 = mlines.Line2D([], [], color=\"C1\", label=\"Instantaneous\")\n",
    "\n",
    "ax.set_xlabel(\"Scaled distribution amplitude (after Gaussian convolution)\")\n",
    "ax.set_ylabel(\"Mean Absolute Error\")\n",
    "ax.set_title(\"Distribution over segments: NN pred (blue) and naive pred (orange)\")\n",
    "plt.legend(handles=(line1, line2), title=\"Prediction Model\", loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##all test result visualization\n",
    "fig1 = plt.figure(figsize=(15, 8))\n",
    "#    ax1 = fig1.add_subplot(1,1,1)\n",
    "a_pred = test_rescpred[:, 100]\n",
    "a_true = test_rescref[:, 100]\n",
    "plt.plot(a_pred, \"r-\", label=\"prediction\")\n",
    "plt.plot(a_true, \"b-\", label=\"true\")\n",
    "plt.xlabel(\"time\")\n",
    "plt.ylabel(\"speed\")\n",
    "plt.legend(loc=\"best\", fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output all results to a sub-directory\n",
    "import datetime\n",
    "import pathlib\n",
    "import os\n",
    "path = pathlib.Path().absolute()\n",
    "time = datetime.datetime.now().strftime(\"%m-%d-%Y %H-%M-%S\")\n",
    "result_dir = os.path.join (path, \"experiments\", time)\n",
    "os.mkdir (result_dir)\n",
    "\n",
    "# Create the result txt file\n",
    "f = open(result_dir + \"/\" + \"summary.txt\", \"w\")\n",
    "\n",
    "# Write experiment parameters\n",
    "f.write (\"---------Experiment Parameters--------\")\n",
    "f.write (\"Past feature window: \", seq_len)\n",
    "f.write (\"Future feature window: \", pre_len)\n",
    "f.write (\"Train-Test split rate: \", train_rate)\n",
    "f.write (\"Number of epochs: \", n_epochs)\n",
    "f.write (\"Batch size: \", batch_size)\n",
    "f.write (\"Shuffle during training: \", shuffle)\n",
    "f.write (\"Verbose: \", verbose)\n",
    "f.write (\"---------------------------\")\n",
    "\n",
    "# Write dataset details\n",
    "f.write (\"---------Dataset Details--------\")\n",
    "num_nodes, time_len = speed_data.shape\n",
    "f.write (\"No. of sensors:\", num_nodes, \"\\nNo of timesteps:\", time_len)\n",
    "f.write (\"Train data: \", train_data.shape)\n",
    "f.write (\"Test data: \", test_data.shape)\n",
    "\n",
    "f.write (\"Train data X: \", trainX.shape)\n",
    "f.write (\"Train data Y: \", trainY.shape)\n",
    "f.write (\"Test data X: \", testX.shape)\n",
    "f.write (\"Test data Y: \", testY.shape)\n",
    "f.write (\"---------------------------\")\n",
    "\n",
    "# Write model details\n",
    "f.write (\"---------Model Details--------\")\n",
    "f.write (\"GCN layer sizes: \", gc_layer_sizes)\n",
    "f.write (\"GCN activation functions: \", gc_activations)\n",
    "f.write (\"LSTM layer sizes: \", lstm_layer_sizes)\n",
    "f.write (\"LSTM activation functions: \", lstm_activations)\n",
    "f.write (\"Optimizer: \", optimizer)\n",
    "f.write (\"Loss function: \", loss)\n",
    "f.write (\"Result Metrics: \", metrics)\n",
    "f.write (\"---------------------------\")\n",
    "\n",
    "# Write results\n",
    "f.write (\"Last Train loss: \", history.history[\"loss\"][-1], \n",
    "         \", Last Test loss:\", history.history[\"val_loss\"][-1])\n",
    "f.write (\"Total (ave) MAE for NN: \" + str(np.mean(np.array(seg_mael))))\n",
    "f.write (\"Total (ave) MAE for naive prediction: \" + str(np.mean(np.array(seg_nmael))))\n",
    "f.write (\"Total (ave) MASE for per-segment NN/naive MAE: \"\n",
    "    + str(np.nanmean(np.array(seg_masel))))\n",
    "f.write (\"...note that MASE<1 (for a given segment) means that the\" + \n",
    "         \"NN prediction is better than the naive prediction.\")\n",
    "\n",
    "# Write visual outputs\n",
    "fig.savefig (result_dir + \"/\" + \"MAE-vs-Naive.png\")\n",
    "fig1.savefig (result_dir + \"/\" + \"prediction-accuracy.png\")\n",
    "\n",
    "f.close ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
