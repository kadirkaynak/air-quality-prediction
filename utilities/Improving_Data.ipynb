{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b062717",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import locale\n",
    "from locale import atof\n",
    "import xlsxwriter\n",
    "\n",
    "from utilities.PreProcessingUtil import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1028e6b",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                    Tarih PM10 ( µg/m3 ) SO2 ( µg/m3 ) CO ( µg/m3 )  \\\n0     2012-01-01 01:00:56              -             -            -   \n1     2012-01-01 02:00:56              -             -            -   \n2     2012-01-01 03:00:56              -             -            -   \n3     2012-01-01 04:00:56              -             -            -   \n4     2012-01-01 05:00:56              -             -            -   \n...                   ...            ...           ...          ...   \n81690 2021-04-26 19:00:56          11,10          1,00       296,70   \n81691 2021-04-26 20:00:56          17,40          0,80       254,10   \n81692 2021-04-26 21:00:56          30,00          0,70       180,00   \n81693 2021-04-26 22:00:56          18,60          1,00       399,00   \n81694 2021-04-26 23:00:56              -          1,10       446,60   \n\n      NO2 ( µg/m3 ) NOX ( µg/m3 ) O3 ( µg/m3 ) PM 2.5 ( µg/m3 )  \n0                 -             -            -                -  \n1                 -             -            -                -  \n2                 -             -            -                -  \n3                 -             -            -                -  \n4                 -             -            -                -  \n...             ...           ...          ...              ...  \n81690         15,90             -        31,60                -  \n81691         15,80             -        34,40                -  \n81692         18,90             -        31,70                -  \n81693         23,30             -        17,10                -  \n81694         22,10             -        22,20                -  \n\n[81695 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel(\n",
    "     os.path.join(\"datasets\", \"pollutants\", \"besiktas.xlsx\"),\n",
    "     engine='openpyxl',\n",
    "     parse_dates=True,\n",
    "     thousands='.'\n",
    ")\n",
    "print (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f48522a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace '-' string with NaN\n",
    "df = df.replace ('-', '-1')\n",
    "\n",
    "# Also fixing ',' delimeter with '.' for float conversion\n",
    "# . is for thousands , for the last delimeter\n",
    "df['PM10 ( µg/m3 )'] = df['PM10 ( µg/m3 )'].astype(str).str.replace('.','')\n",
    "df['PM10 ( µg/m3 )'] = df['PM10 ( µg/m3 )'].astype(str).str.replace(',','.')\n",
    "\n",
    "# Casting str to float\n",
    "df['PM10 ( µg/m3 )'] = pd.to_numeric(df['PM10 ( µg/m3 )'], downcast=\"float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a1f85ef",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/deneme/opt/anaconda3/lib/python3.7/site-packages/pandas/core/ops/__init__.py:1115: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n  result = method(y)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Tarih                   0\n",
       "PM10 ( µg/m3 )          0\n",
       "SO2 ( µg/m3 )       61745\n",
       "CO ( µg/m3 )        62154\n",
       "NO2 ( µg/m3 )       63773\n",
       "NOX ( µg/m3 )       67718\n",
       "O3 ( µg/m3 )        62743\n",
       "PM 2.5 ( µg/m3 )    67638\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "# Counting number of -1 in the column\n",
    "df[df == '-1'].count () "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b29120fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling empty rows\n",
    "# https://towardsdatascience.com/7-ways-to-handle-missing-values-in-machine-learning-1a6326adf79e\n",
    "# 1- We cant just delete them because we need consistent timestamps\n",
    "# 2- If too many empty rows exists we should discard them\n",
    "# 3- Replacing missing data with mean/median\n",
    "# 3.1- This does not cover the covariance between features\n",
    "df['PM10 ( µg/m3 )'] = df['PM10 ( µg/m3 )'].replace (-1.0, df[df != -1]['PM10 ( µg/m3 )'].median ())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1dc3118f",
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0        26.1\n",
       "1        26.1\n",
       "2        26.1\n",
       "3        26.1\n",
       "4        26.1\n",
       "         ... \n",
       "81690    11.1\n",
       "81691    17.4\n",
       "81692    30.0\n",
       "81693    18.6\n",
       "81694    26.1\n",
       "Name: PM10 ( µg/m3 ), Length: 81695, dtype: float32"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "df['PM10 ( µg/m3 )']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbc0e57",
   "metadata": {},
   "source": [
    "## Town - Pollution Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e90e8f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dataframes per town\n",
    "dfAksaray = pd.read_excel(os.path.join(\"datasets\", \"pollutants\", \"aksaray.xlsx\"),engine='openpyxl',parse_dates=True,thousands='.')\n",
    "dfBesiktas = pd.read_excel(os.path.join(\"datasets\", \"pollutants\", \"besiktas.xlsx\"),engine='openpyxl',parse_dates=True,thousands='.')\n",
    "dfBuyukada = pd.read_excel(os.path.join(\"datasets\", \"pollutants\", \"buyukada.xlsx\"),engine='openpyxl',parse_dates=True,thousands='.')\n",
    "dfCatladıkapı = pd.read_excel(os.path.join(\"datasets\", \"pollutants\", \"catladıkapı.xlsx\"),engine='openpyxl',parse_dates=True,thousands='.')\n",
    "dfEsenler = pd.read_excel(os.path.join(\"datasets\", \"pollutants\", \"esenler.xlsx\"),engine='openpyxl',parse_dates=True,thousands='.')\n",
    "dfKadıkoy = pd.read_excel(os.path.join(\"datasets\", \"pollutants\", \"kadıkoy.xlsx\"),engine='openpyxl',parse_dates=True,thousands='.')\n",
    "dfKandilli = pd.read_excel(os.path.join(\"datasets\", \"pollutants\", \"kandilli.xlsx\"),engine='openpyxl',parse_dates=True,thousands='.')\n",
    "dfKartal = pd.read_excel(os.path.join(\"datasets\", \"pollutants\", \"kartal.xlsx\"),engine='openpyxl',parse_dates=True,thousands='.')\n",
    "dfMecidiyekoy = pd.read_excel(os.path.join(\"datasets\", \"pollutants\", \"mecidiyekoy.xlsx\"),engine='openpyxl',parse_dates=True,thousands='.')\n",
    "dfUmraniye = pd.read_excel(os.path.join(\"datasets\", \"pollutants\", \"umraniye.xlsx\"),engine='openpyxl',parse_dates=True,thousands='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def fixValues(df):\n",
    "    # Replace '-' string with NaN\n",
    "    df = df.replace ('-', '-1')\n",
    "\n",
    "    # Also fixing ',' delimeter with '.' for float conversion '.' is for thousands , for the last delimeter\n",
    "    # Casting str to float\n",
    "    df['PM10 ( µg/m3 )'] = df['PM10 ( µg/m3 )'].astype(str).str.replace('.','')\n",
    "    df['PM10 ( µg/m3 )'] = df['PM10 ( µg/m3 )'].astype(str).str.replace(',','.')\n",
    "    df['PM10 ( µg/m3 )'] = pd.to_numeric(df['PM10 ( µg/m3 )'], downcast=\"float\")\n",
    "    \n",
    "    df['SO2 ( µg/m3 )'] = df['SO2 ( µg/m3 )'].astype(str).str.replace('.','')\n",
    "    df['SO2 ( µg/m3 )'] = df['SO2 ( µg/m3 )'].astype(str).str.replace(',','.')\n",
    "    df['SO2 ( µg/m3 )'] = pd.to_numeric(df['SO2 ( µg/m3 )'], downcast=\"float\")\n",
    "    \n",
    "    df['CO ( µg/m3 )'] = df['CO ( µg/m3 )'].astype(str).str.replace('.','')\n",
    "    df['CO ( µg/m3 )'] = df['CO ( µg/m3 )'].astype(str).str.replace(',','.')\n",
    "    df['CO ( µg/m3 )'] = pd.to_numeric(df['CO ( µg/m3 )'], downcast=\"float\")\n",
    "    \n",
    "    df['NO2 ( µg/m3 )'] = df['NO2 ( µg/m3 )'].astype(str).str.replace('.','')\n",
    "    df['NO2 ( µg/m3 )'] = df['NO2 ( µg/m3 )'].astype(str).str.replace(',','.')\n",
    "    df['NO2 ( µg/m3 )'] = pd.to_numeric(df['NO2 ( µg/m3 )'], downcast=\"float\")\n",
    "    \n",
    "    df['NOX ( µg/m3 )'] = df['NOX ( µg/m3 )'].astype(str).str.replace('.','')\n",
    "    df['NOX ( µg/m3 )'] = df['NOX ( µg/m3 )'].astype(str).str.replace(',','.')\n",
    "    df['NOX ( µg/m3 )'] = pd.to_numeric(df['NOX ( µg/m3 )'], downcast=\"float\")\n",
    "    \n",
    "    df['O3 ( µg/m3 )'] = df['O3 ( µg/m3 )'].astype(str).str.replace('.','')\n",
    "    df['O3 ( µg/m3 )'] = df['O3 ( µg/m3 )'].astype(str).str.replace(',','.')\n",
    "    df['O3 ( µg/m3 )'] = pd.to_numeric(df['O3 ( µg/m3 )'], downcast=\"float\")\n",
    "    \n",
    "    df['PM 2.5 ( µg/m3 )'] = df['PM 2.5 ( µg/m3 )'].astype(str).str.replace('.','')\n",
    "    df['PM 2.5 ( µg/m3 )'] = df['PM 2.5 ( µg/m3 )'].astype(str).str.replace(',','.')\n",
    "    df['PM 2.5 ( µg/m3 )'] = pd.to_numeric(df['PM 2.5 ( µg/m3 )'], downcast=\"float\")\n",
    "    \n",
    "    return df\n",
    "    \n",
    "def fillEmptyRows(df):\n",
    "    # Filling empty rows\n",
    "    # https://towardsdatascience.com/7-ways-to-handle-missing-values-in-machine-learning-1a6326adf79e\n",
    "    # 1- We cant just delete them because we need consistent timestamps\n",
    "    # 2- If too many empty rows exists we should discard them\n",
    "    # 3- Replacing missing data with mean/median\n",
    "    # 3.1- This does not cover the covariance between features\n",
    "    \n",
    "    #df['PM10 ( µg/m3 )'] = df['PM10 ( µg/m3 )'].replace (-1.0, df[df != -1]['PM10 ( µg/m3 )'].median ())\n",
    "    #df['SO2 ( µg/m3 )'] = df['SO2 ( µg/m3 )'].replace (-1.0, df[df != -1]['SO2 ( µg/m3 )'].median ())\n",
    "    #df['CO ( µg/m3 )'] = df['CO ( µg/m3 )'].replace (-1.0, df[df != -1]['CO ( µg/m3 )'].median ())\n",
    "    #df['NO2 ( µg/m3 )'] = df['NO2 ( µg/m3 )'].replace (-1.0, df[df != -1]['NO2 ( µg/m3 )'].median ())\n",
    "    #df['NOX ( µg/m3 )'] = df['NOX ( µg/m3 )'].replace (-1.0, df[df != -1]['NOX ( µg/m3 )'].median ())\n",
    "    #df['O3 ( µg/m3 )'] = df['O3 ( µg/m3 )'].replace (-1.0, df[df != -1]['O3 ( µg/m3 )'].median ())\n",
    "    #df['PM 2.5 ( µg/m3 )'] = df['PM 2.5 ( µg/m3 )'].replace (-1.0, df[df != -1]['PM 2.5 ( µg/m3 )'].median ())\n",
    "    if not(df['PM10 ( µg/m3 )'][df['PM10 ( µg/m3 )']!=-1].count()>0):df['PM10 ( µg/m3 )']=0\n",
    "    if not(df['SO2 ( µg/m3 )'][df['SO2 ( µg/m3 )']!=-1].count()>0):df['SO2 ( µg/m3 )']=0\n",
    "    if not(df['CO ( µg/m3 )'][df['CO ( µg/m3 )']!=-1].count()>0):df['CO ( µg/m3 )']=0\n",
    "    if not(df['NO2 ( µg/m3 )'][df['NO2 ( µg/m3 )']!=-1].count()>0):df['NO2 ( µg/m3 )']=0\n",
    "    if not(df['NOX ( µg/m3 )'][df['NOX ( µg/m3 )']!=-1].count()>0):df['NOX ( µg/m3 )']=0\n",
    "    if not(df['O3 ( µg/m3 )'][df['O3 ( µg/m3 )']!=-1].count()>0):df['O3 ( µg/m3 )']=0\n",
    "    if not(df['PM 2.5 ( µg/m3 )'][df['PM 2.5 ( µg/m3 )']!=-1].count()>0):df['PM 2.5 ( µg/m3 )']=0\n",
    "\n",
    "    #if not(df['PM10 ( µg/m3 )'].notnull().values.any()): df['PM10 ( µg/m3 )']=0\n",
    "    #if not(df['SO2 ( µg/m3 )'].notnull().values.any()): df['SO2 ( µg/m3 )']=0\n",
    "    #if not(df['CO ( µg/m3 )'].notnull().values.any()): df['CO ( µg/m3 )']=0\n",
    "    #if not(df['NO2 ( µg/m3 )'].notnull().values.any()): df['NO2 ( µg/m3 )']=0\n",
    "    #if not(df['NOX ( µg/m3 )'].notnull().values.any()): df['NOX ( µg/m3 )']=0\n",
    "    #if not(df['O3 ( µg/m3 )'].notnull().values.any()): df['O3 ( µg/m3 )']=0\n",
    "    #if not(df['PM 2.5 ( µg/m3 )'].notnull().values.any()): df['PM 2.5 ( µg/m3 )']=0\n",
    "\n",
    "    df = fillWithSameHourValue(df, 'PM10 ( µg/m3 )')\n",
    "    df = fillWithSameHourValue(df, 'SO2 ( µg/m3 )')\n",
    "    df = fillWithSameHourValue(df, 'CO ( µg/m3 )')\n",
    "    df = fillWithSameHourValue(df, 'NO2 ( µg/m3 )')\n",
    "    df = fillWithSameHourValue(df, 'NOX ( µg/m3 )')\n",
    "    df = fillWithSameHourValue(df, 'O3 ( µg/m3 )')\n",
    "    df = fillWithSameHourValue(df, 'PM 2.5 ( µg/m3 )')\n",
    "    return df\n",
    "\n",
    "def fillWithSameHourValue(df, pollutantColumnName):\n",
    "    for x in range (df[pollutantColumnName].shape[0]):\n",
    "        if(df[pollutantColumnName].iloc[x] == -1 and x < 24):\n",
    "            df[pollutantColumnName].iloc[x] = findValue(df[pollutantColumnName], x)\n",
    "        if(df[pollutantColumnName].iloc[x] == -1 and x >= 24):\n",
    "            df[pollutantColumnName].iloc[x] = df[pollutantColumnName].iloc[x-24]\n",
    "        \n",
    "    return df\n",
    "\n",
    "def findValue(df, i):\n",
    "    if(df.shape[0]<=i):\n",
    "        return 0\n",
    "\n",
    "    if(df.iloc[i] == -1):\n",
    "        i = i+24\n",
    "        return findValue(df, i)\n",
    "    else:\n",
    "        return df.iloc[i] \n",
    "\n",
    "def preprocessingx(df):\n",
    "    df = fixValues(df)\n",
    "    df = fillEmptyRows(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49f226e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making preprocessing (fixing values, filling empty rows)\n",
    "dfAksaray = preprocessing(dfAksaray)\n",
    "dfBesiktas = preprocessing(dfBesiktas)\n",
    "dfBuyukada = preprocessing(dfBuyukada)\n",
    "dfCatladıkapı = preprocessing(dfCatladıkapı)\n",
    "dfEsenler = preprocessing(dfEsenler)\n",
    "dfKadıkoy = preprocessing(dfKadıkoy)\n",
    "dfKandilli = preprocessing(dfKandilli)\n",
    "dfKartal = preprocessing(dfKartal)\n",
    "dfMecidiyekoy = preprocessing(dfMecidiyekoy)\n",
    "dfUmraniye = preprocessing(dfUmraniye)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aad4e22",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initialize data to Dicts of series.  \n",
    "lastNItems = 20000\n",
    "columnName = 'PM10 ( µg/m3 )'\n",
    "excelName = 'datasets/training/PM10.xlsx'\n",
    "\n",
    "d = {\n",
    "    'Aksaray' : dfAksaray[columnName][-lastNItems:].tolist(),  \n",
    "    'Besiktas' : dfBesiktas[columnName][-lastNItems:].tolist(),\n",
    "    'Buyukada' : dfBuyukada[columnName][-lastNItems:].tolist(), \n",
    "    'Catladıkapı' : dfCatladıkapı[columnName][-lastNItems:].tolist(),\n",
    "    'Esenler' : dfEsenler[columnName][-lastNItems:].tolist(), \n",
    "    'Kadıkoy' : dfKadıkoy[columnName][-lastNItems:].tolist(),\n",
    "    'Kandilli' : dfKandilli[columnName][-lastNItems:].tolist(), \n",
    "    'Kartal'    : dfKartal[columnName][-lastNItems:].tolist(),\n",
    "    'Mecidiyekoy' : dfMecidiyekoy[columnName][-lastNItems:].tolist(), \n",
    "    'Umraniye'    : dfUmraniye[columnName][-lastNItems:].tolist()\n",
    "    \n",
    "}  \n",
    "  \n",
    "# creates Dataframe.  \n",
    "dframe = pd.DataFrame(d, columns = ['Aksaray', 'Besiktas','Buyukada','Catladıkapı','Esenler','Kadıkoy','Kandilli','Kartal','Mecidiyekoy','Umraniye']) \n",
    "  \n",
    "# print the data.  \n",
    "print(dframe) \n",
    "\n",
    "# export to excel\n",
    "dframe.to_excel(excelName) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pollution Diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sehirList = ['Aksaray', 'Besiktas','Buyukada','Catladıkapı','Esenler','Kadıkoy','Kandilli','Kartal','Mecidiyekoy','Umraniye']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sensors = len(sehirList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dframe['Aksaray']-dframe['Besiktas']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing adjacency matrix for the sensor nodes\n",
    "pol_diff_matrix = np.zeros ((n_sensors, n_sensors))\n",
    "\n",
    "# Create distance matrix from each sensor to other ones\n",
    "# For each sensor\n",
    "ix = 0\n",
    "for s_sehir in sehirList:\n",
    "    s = dframe[s_sehir]\n",
    "    # Look at other sensors\n",
    "    o_ix = 0\n",
    "    for o_sehir in sehirList:\n",
    "        o = dframe[o_sehir]\n",
    "        # Calculate the distance\n",
    "        dframe['diff'] = s-o\n",
    "        # Update the distance matrix\n",
    "        pol_diff_matrix [ix][o_ix] = abs(dframe['diff'].mean())\n",
    "        #\n",
    "        o_ix += 1\n",
    "    ix += 1\n",
    "    \n",
    "# Take the absolute of the difference between all values and the max value\n",
    "# Then divide it by the max value to get the weighted adjacency matrix\n",
    "# Add 1 to the max value so that the weights will never be lost\n",
    "max_val = np.max (pol_diff_matrix) + 1\n",
    "pol_diff_matrix = (max_val - pol_diff_matrix)/max_val\n",
    "pol_diff_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export to excel\n",
    "workbook = xlsxwriter.Workbook('datasets/training/pol_diff_adj.xlsx')\n",
    "worksheet = workbook.add_worksheet()\n",
    "\n",
    "row = 0\n",
    "\n",
    "for col, data in enumerate(pol_diff_matrix):\n",
    "    worksheet.write_column(row, col, data)\n",
    "\n",
    "workbook.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "36e82d28",
   "metadata": {},
   "source": [
    "## Sensor Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311e2f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import cos, asin, sqrt, pi\n",
    "\n",
    "# Distance between two coordinates taken from\n",
    "# https://stackoverflow.com/questions/27928/calculate-distance-between-two-latitude-longitude-points-haversine-formula\n",
    "def coord_distance(lat1, lon1, lat2, lon2):\n",
    "    p = pi/180\n",
    "    a = 0.5 - cos((lat2-lat1)*p)/2 + cos(lat1*p) * cos(lat2*p) * (1-cos((lon2-lon1)*p))/2\n",
    "    return 12742 * asin(sqrt(a)) #2*R*asin..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f12573",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_l = pd.read_excel(\n",
    "     os.path.join(\"datasets/adjacency/sensor_locations.xlsx\"),\n",
    "     engine='openpyxl',\n",
    "     parse_dates=True,\n",
    ")\n",
    "n_sensors = sensor_l.shape[0]\n",
    "print (sensor_l)\n",
    "print (sensor_l.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0326e776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing adjacency matrix for the sensor nodes\n",
    "distance_matrix = np.zeros ((n_sensors, n_sensors))\n",
    "\n",
    "# Create distance matrix from each sensor to other ones\n",
    "# For each sensor\n",
    "ix = 0\n",
    "for sensor in sensor_l['İlçe']:\n",
    "    s_lat = sensor_l[sensor_l['İlçe'] == sensor].values[0][1]\n",
    "    s_lon = sensor_l[sensor_l['İlçe'] == sensor].values[0][2]\n",
    "    # Look at other sensors\n",
    "    o_ix = 0\n",
    "    for o_sensor in sensor_l['İlçe']:\n",
    "        o_lat = sensor_l[sensor_l['İlçe'] == o_sensor].values[0][1] \n",
    "        o_lon = sensor_l[sensor_l['İlçe'] == o_sensor].values[0][2] \n",
    "        # Calculate the distance\n",
    "        distance = coord_distance (s_lat, s_lon, o_lat, o_lon)\n",
    "        # Update the distance matrix\n",
    "        distance_matrix [ix][o_ix] = distance\n",
    "        #\n",
    "        o_ix += 1\n",
    "    ix += 1\n",
    "    \n",
    "# Take the absolute of the difference between all values and the max value\n",
    "# Then divide it by the max value to get the weighted adjacency matrix\n",
    "# Add 1 to the max value so that the weights will never be lost\n",
    "max_val = np.max (distance_matrix) + 1\n",
    "distance_matrix = (max_val - distance_matrix)/max_val\n",
    "distance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74783033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export to excel\n",
    "workbook = xlsxwriter.Workbook('datasets/training/sensor_dist_adj.xlsx')\n",
    "worksheet = workbook.add_worksheet()\n",
    "\n",
    "row = 0\n",
    "\n",
    "for col, data in enumerate(distance_matrix):\n",
    "    worksheet.write_column(row, col, data)\n",
    "\n",
    "workbook.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa4e520",
   "metadata": {},
   "source": [
    "## Population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54aa56ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_l = pd.read_excel(\n",
    "     os.path.join(\"datasets/adjacency/population.xlsx\"),\n",
    "     engine='openpyxl',\n",
    "     parse_dates=True,\n",
    ")\n",
    "n_sensors = sensor_l.shape[0]\n",
    "print (sensor_l)\n",
    "print (sensor_l.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb114c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python374jvsc74a57bd0fc9c1e1bd2f958361b34454cff99611c970e5cf7b1a4a61c9cc910440db53ba1",
   "display_name": "Python 3.7.4 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "metadata": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}